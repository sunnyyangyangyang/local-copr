#!/usr/bin/env python3
#
# Local Copr (lc) - A lightweight local RPM build system
# Copyright (C) 2026 Yuanxi (Sunny) Yang
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
import re
import os
import sys
import argparse
import subprocess
import glob
import shutil
import tempfile
import tarfile
import json
from datetime import datetime

# --- é…ç½®å¸¸é‡ ---
tool_name = "lc (Local-Copr)"
CONFIG_FILE = ".lc_config" # å­˜å‚¨ä»“åº“é…ç½®ï¼ˆå¦‚GPG Key IDï¼‰

def run_cmd(cmd, cwd=None, env=None, capture_output=False):
    """å°è£… subprocess"""
    if not capture_output:
        print(f"[{tool_name}] CMD: {' '.join(cmd)}")
    try:
        if capture_output:
            return subprocess.check_output(cmd, cwd=cwd, env=env, text=True).strip()
        subprocess.run(cmd, cwd=cwd, env=env, check=True)
    except subprocess.CalledProcessError as e:
        print(f"Error executing command: {e}")
        sys.exit(1)

def do_init(args):
    """åˆå§‹åŒ–ä»“åº“"""
    repo_path = os.path.abspath(args.repo)
    gpg_key = args.gpg_key
    
    print(f"[{tool_name}] Initializing repo at: {repo_path}")
    
    if not os.path.exists(repo_path):
        os.makedirs(repo_path)
    
    # 1. è®°å½•é…ç½® (GPG ID)
    config = {}
    if gpg_key:
        print(f"[{tool_name}] GPG Signing Enabled. Key ID: {gpg_key}")
        config["gpg_key_id"] = gpg_key
        
        # 2. å¯¼å‡ºå…¬é’¥åˆ°ä»“åº“æ ¹ç›®å½•
        pub_key_path = os.path.join(repo_path, "RPM-GPG-KEY-local")
        print(f"-> Exporting public key to {pub_key_path}...")
        with open(pub_key_path, "w") as f:
            subprocess.run(["gpg", "--export", "--armor", gpg_key], stdout=f, check=True)

    # [æ–°å¢] ä¿å­˜ Rebuild è®¾ç½®    
    if args.enable_rebuild:
        print(f"[{tool_name}] ğŸ”„ Auto-Rebuild (Chain) Enabled.")
        config["auto_rebuild"] = True
    else:
        config["auto_rebuild"] = False
        
    with open(os.path.join(repo_path, CONFIG_FILE), "w") as f:
        json.dump(config, f)

    # ä¿å­˜ .lc_config
    with open(os.path.join(repo_path, CONFIG_FILE), "w") as f:
        json.dump(config, f)

    # 3. åˆå§‹åŒ– Repodata
    run_cmd(["createrepo_c", repo_path])
    if gpg_key:
        sign_repodata(repo_path, gpg_key)
    # 4. ç”Ÿæˆ .repo æ¨¡æ¿
    repo_name = os.path.basename(repo_path)
    if gpg_key:
        # å¼€å¯ GPG æ£€æŸ¥
        gpg_block = f"""gpgcheck=1
repo_gpgcheck=1
gpgkey=file://{repo_path}/RPM-GPG-KEY-local"""
    else:
        # å…³é—­ GPG æ£€æŸ¥
        gpg_block = "gpgcheck=0"

    readme_content = f"""[{repo_name}]
name=Local Copr - {repo_name}
baseurl=file://{repo_path}
enabled=1
{gpg_block}
"""
    readme_path = os.path.join(repo_path, "local.repo")
    with open(readme_path, "w") as f:
        f.write(readme_content)
        
    print(f"[{tool_name}] Success. Repo config template saved to {readme_path}")

def do_delete(args):
    """åˆ é™¤ä»“åº“"""
    repo_path = os.path.abspath(args.repo)
    # å®‰å…¨æ£€æŸ¥ (ç•¥ï¼Œä¿æŒåŸæœ‰é€»è¾‘)
    forbidden_paths = ["/", "/home", "/usr", "/var", "/etc", os.path.expanduser("~")]
    if repo_path in forbidden_paths:
        sys.exit(1)
    if not os.path.exists(repo_path):
        print(f"Error: Repo {repo_path} does not exist.")
        sys.exit(1)
        
    print(f"!!! WARNING !!! Delete {repo_path}?")
    if input("Type 'yes': ").lower() == "yes":
        shutil.rmtree(repo_path)
        print("Deleted.")

def sign_rpms(repo_path, rpm_files, key_id):
    """å¯¹ RPM æ–‡ä»¶è¿›è¡Œç­¾å"""
    if not rpm_files:
        return
    print(f"--- Signing {len(rpm_files)} RPMs with Key {key_id} ---")
    # ä½¿ç”¨ rpm --addsign
    # æ³¨æ„ï¼šè¿™éœ€è¦ gpg-agent å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œå¦åˆ™ä¼šå¼¹å‡ºå¯†ç è¾“å…¥æ¡†æˆ–æŠ¥é”™
    cmd = ["rpm", "--addsign", "--define", f"_gpg_name {key_id}"] + rpm_files
    run_cmd(cmd)

def sign_repodata(repo_path, key_id):
    """å¯¹ repomd.xml è¿›è¡Œç­¾å"""
    repodata_xml = os.path.join(repo_path, "repodata", "repomd.xml")
    if os.path.exists(repodata_xml):
        print(f"--- Signing repodata with Key {key_id} ---")
        # ç”Ÿæˆ repomd.xml.asc
        # --yes è¦†ç›–æ—§ç­¾å
        cmd = ["gpg", "--detach-sign", "--armor", "--yes", "--default-key", key_id, repodata_xml]
        run_cmd(cmd)

def _bump_spec_release(spec_path):
    """
    ä¿®æ”¹ Spec æ–‡ä»¶ï¼Œè¿½åŠ åŸºäºæ—¶é—´æˆ³çš„ Patch å·ï¼Œç¡®ä¿ç‰ˆæœ¬å•è°ƒé€’å¢ã€‚
    ä¾‹å¦‚: Release: 1%{?dist} -> Release: 1.p1700000000%{?dist}
    """
    import time
    import re
    
    try:
        with open(spec_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        new_lines = []
        # ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ—¶é—´æˆ³ patch å· (ä¾‹å¦‚ .p1704895000)
        patch_suffix = f".p{int(time.time())}"
        changed = False

        # åŒ¹é… Release è¡Œï¼Œå¿½ç•¥å¤§å°å†™
        release_pattern = re.compile(r'^(Release:\s*)(.+?)(%\{\?dist\})?$', re.IGNORECASE)

        for line in lines:
            match = release_pattern.match(line.strip())
            if match and not changed:
                # group(1): "Release: "
                # group(2): "1" æˆ– "1.p12345"
                # group(3): "%{?dist}" æˆ– None
                prefix = match.group(1)
                old_ver = match.group(2).strip()
                dist_macro = match.group(3) if match.group(3) else ""
                
                # å¦‚æœä»¥å‰å·²ç»bumpè¿‡ (åŒ…å« .p1...), æˆ‘ä»¬å»æ‰æ—§åç¼€å†åŠ æ–°çš„
                # è¿™æ ·ä¿è¯ git é‡Œæ— è®ºæ€ä¹ˆæ”¹ï¼Œæ„å»ºå‡ºæ¥çš„æ€»æ˜¯æœ€æ–°çš„
                base_ver = re.sub(r'\.p\d+$', '', old_ver)
                
                new_line = f"{prefix}{base_ver}{patch_suffix}{dist_macro}\n"
                new_lines.append(new_line)
                print(f"[{tool_name}] ğŸ†™ Version Bump: {old_ver} -> {base_ver}{patch_suffix}")
                changed = True
            else:
                new_lines.append(line)
        
        with open(spec_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
            
    except Exception as e:
        print(f"[{tool_name}] Warning: Failed to bump spec release: {e}")

def do_build(args):
    """æ‰§è¡Œæ„å»ºæµç¨‹"""
    repo_dir = os.path.abspath(args.torepo)

    # --- [æ–°å¢] Chain Mode æ‹¦æˆª (çº¿æ€§ Loop) ---
    if args.chain:
        print(f"[{tool_name}] â›“ï¸  Chain Mode Triggered: {args.chain}")
        try:
            with open(args.chain) as f:
                tasks = json.load(f).get('tasks', [])
        except Exception as e:
            print(f"Error loading plan: {e}")
            return False

        total = len(tasks)
        print(f"[{tool_name}] Total tasks in chain: {total}")

        for idx, task in enumerate(tasks):
            pkg_name = task['package']
            print(f"\n[{tool_name}] â© Chain Task ({idx+1}/{total}): {pkg_name}")
            
            # ä¼ªè£…å‚æ•°ï¼Œè°ƒç”¨è‡ªèº«
            # æ³¨æ„ï¼šæˆ‘ä»¬è¦æ·±æ‹·è´ args æˆ–è€…ç›´æ¥ä¿®æ”¹ï¼Œå› ä¸ºæ˜¯çº¿æ€§æ‰§è¡Œï¼Œç›´æ¥æ”¹æ²¡é—®é¢˜
            args.chain = None # å¿…é¡»æ¸…é™¤ï¼Œé˜²æ­¢é€’å½’
            args.source = os.path.join(repo_dir, "forges", pkg_name)
            
            # é€’å½’è°ƒç”¨ (å¤ç”¨æ‰€æœ‰é€»è¾‘)
            if not do_build(args):
                print(f"[{tool_name}] âŒ Chain broken at {pkg_name}. Stopping.")
                return False # ä¸­æ–­é“¾æ¡
            
            # æ³¨æ„ï¼šdo_build ç»“å°¾è‡ªå¸¦ createrepoï¼Œæ‰€ä»¥è¿™é‡Œä¸ç”¨å†™
            # ä¸‹ä¸€æ¬¡å¾ªç¯æ—¶ï¼ŒRepo å·²ç»æ˜¯æ–°çš„äº†
            
        print(f"[{tool_name}] ğŸ‰ Chain Execution Completed.")
        return True

    source_dir_origin = os.path.abspath(args.source)

    # è¯»å–ä»“åº“é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨ GPG
    gpg_key_id = None
    config_path = os.path.join(repo_dir, CONFIG_FILE)
    if os.path.exists(config_path):
        try:
            with open(config_path, "r") as f:
                cfg = json.load(f)
                gpg_key_id = cfg.get("gpg_key_id")
        except:
            pass

    # Mock åŸºç¡€å‚æ•°
    mock_base_args = ["unbuffer","mock", "--define", "_changelog_date_check 0"]

    if args.max_mem:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æœ‰ systemd-run
        if not shutil.which("systemd-run"):
            print(f"[{tool_name}] Error: --max-mem requires 'systemd-run', but it's not found.")
            sys.exit(1)
            
        print(f"[{tool_name}] ğŸ›¡ï¸  Enforcing Memory Limit: {args.max_mem}")
        # å°† systemd-run å‘½ä»¤æ‹¼æ¥åˆ° mock å‘½ä»¤åˆ—è¡¨çš„æœ€å‰é¢
        # æ•ˆæœç­‰åŒäº: systemd-run --scope --user -p MemoryMax=4G mock ...
        wrapper = ["systemd-run", "--scope", "--user", "--quiet", "-p", f"MemoryMax={args.max_mem}"]
        mock_base_args = wrapper + mock_base_args

    if args.enable_network:
        print(f"[{tool_name}] ğŸŒ Network access enabled for this build.")
        # æ˜¾å¼å‘Šè¯‰ mock å¼€å¯ç½‘ç»œ
        mock_base_args.append("--enable-network")
    else:
        print(f"[{tool_name}] Network access enabled for this build.")

    if not (args.use_ssd or args.use_tmp_ssd):
        mock_base_args.append("--enable-plugin=tmpfs")
    if args.use_tmp_ssd:
        mock_base_args.append("--enable-plugin=tmpfs_tmponly")
    if args.jobs:
        print(f"[{tool_name}] Limiting concurrency to: -j{args.jobs}")
        # è¦†ç›– _smp_mflags å®ï¼Œå¼ºåˆ¶ rpmbuild ä½¿ç”¨æŒ‡å®šæ ¸å¿ƒæ•°
        mock_base_args.extend(["--define", f"_smp_mflags -j{args.jobs}"])

    # è·¯å¾„æ£€æŸ¥ (ç•¥)
    if not os.path.isdir(source_dir_origin): sys.exit(1)
    if not os.path.isdir(repo_dir): sys.exit(1)

    # ç¡®å®š Spec
    spec_file_arg = args.spec
    if spec_file_arg:
        spec_path_origin = os.path.abspath(spec_file_arg)
    else:
        specs = glob.glob(os.path.join(source_dir_origin, "*.spec"))
        if not specs: sys.exit(1)
        spec_path_origin = specs[0]

    # å·¥ä½œåŒº
    with tempfile.TemporaryDirectory(prefix="lc-build-") as work_dir:
        # åˆå§‹åŒ–çŠ¶æ€å˜é‡ï¼Œé˜²æ­¢ UnboundLocalError
        build_success = False
        spec_name = os.path.basename(spec_path_origin).replace('.spec','')
        # é»˜è®¤æ—¥å¿—æºæ˜¯æ•´ä¸ªå·¥ä½œåŒºï¼ˆä»¥é˜²åœ¨ç”Ÿæˆ rpm_result ä¹‹å‰å°±æŒ‚äº†ï¼‰
        log_source_dir = work_dir 
        rpm_result_dir = None 

        try:
            # Step 0: Copy Source to RAM
            print(f"[{tool_name}] Preparing sources...")
            temp_src_dir = os.path.join(work_dir, "clean_sources")
            shutil.copytree(source_dir_origin, temp_src_dir, dirs_exist_ok=True, 
                            ignore=shutil.ignore_patterns('.git', '.svn'))
            rel_spec_path = os.path.relpath(spec_path_origin, source_dir_origin)
            temp_spec_path = os.path.join(temp_src_dir, rel_spec_path)

            # æ›´æ–° spec_name ä»¥é˜²ä¸‡ä¸€
            spec_name = os.path.basename(temp_spec_path).replace('.spec','')

            # Step A: Spectool
            run_cmd(["spectool", "-g", "-C", temp_src_dir, temp_spec_path], cwd=temp_src_dir)

            # --- [æ–°å¢] è‡ªåŠ¨ Bump ç‰ˆæœ¬å· ---
            # åªæœ‰åœ¨æ˜¯åœ¨ temp_src_dir ä¸‹ä¿®æ”¹ï¼Œä¸å½±å“ git æºç 
            # temp_spec_path æ˜¯ spectool ä¹‹åç¡®å®šçš„ spec è·¯å¾„
            _bump_spec_release(temp_spec_path)

            # Step B: SRPM
            srpm_result_dir = os.path.join(work_dir, "srpm_result")
            os.makedirs(srpm_result_dir)
            cmd_srpm: list[str] = mock_base_args + ["--buildsrpm", "--spec", temp_spec_path, "--sources", temp_src_dir, "--resultdir", srpm_result_dir]
            run_cmd(cmd_srpm)
            src_rpms = glob.glob(os.path.join(srpm_result_dir, "*.src.rpm"))
            if not src_rpms:
                raise Exception("SRPM creation failed, no file found.")
            target_srpm = src_rpms[0]

            # Step C: RPM
            rpm_result_dir = os.path.join(work_dir, "rpm_result")
            os.makedirs(rpm_result_dir)
            cmd_rpm = mock_base_args + ["--rebuild", target_srpm, "--resultdir", rpm_result_dir]
        
            # å…³é”®ï¼šæ— æ¡ä»¶æ³¨å…¥è‡ªå·±ï¼Œè®©ä¾èµ–èƒ½æ‰¾åˆ°
            cmd_rpm.append(f"--addrepo=file://{repo_dir}")

            if args.addrepo:
                for repo in args.addrepo:
                    repo_url = f"file://{os.path.abspath(repo)}" if os.path.exists(repo) else repo
                    cmd_rpm.append(f"--addrepo={repo_url}")
            
            # æ‰§è¡Œæ„å»º
            run_cmd(cmd_rpm)

            # --- æ„å»ºæˆåŠŸé€»è¾‘ ---
            
            # Step D: Move RPMs to Repo
            new_rpms = [] 
            built_rpms = glob.glob(os.path.join(rpm_result_dir, "*.rpm"))
            for rpm in built_rpms:
                if "debuginfo" in rpm or rpm.endswith(".src.rpm"): continue
                dest = shutil.copy2(rpm, repo_dir)
                new_rpms.append(dest)
                print(f"-> Saved RPM: {os.path.basename(rpm)}")

            # GPG ç­¾å (RPM Level)
            if gpg_key_id:
                sign_rpms(repo_dir, new_rpms, gpg_key_id)
            
            # æ„å»ºæˆåŠŸï¼Œæ ‡è®°ä¸º True
            build_success = True
            # å¦‚æœæˆåŠŸï¼Œæˆ‘ä»¬é€šå¸¸åªå…³å¿ƒ rpm_result_dir é‡Œçš„æ—¥å¿—ï¼ˆroot.log, build.log ç­‰ï¼‰
            # å½“ç„¶ä½ ä¹Ÿå¯ä»¥ä¿æŒ log_source_dir = work_dir æ¥ä¿å­˜æ‰€æœ‰ä¸œè¥¿
            log_source_dir = rpm_result_dir

        except Exception as e:
            print(f"[{tool_name}] âŒ Build Process Error: {e}")
            build_success = False
            # å¤±è´¥æ—¶ï¼Œæˆ‘ä»¬ä¿å­˜æ•´ä¸ª work_dir ä»¥ä¾¿è°ƒè¯•ï¼ˆåŒ…å«æºç ã€srpmç­‰ï¼‰
            log_source_dir = work_dir

        finally:
            # --- ç»Ÿä¸€çš„ History/Log ä¿å­˜é€»è¾‘ ---
            # åªè¦ä»£ç è¿˜åœ¨è¿™ä¸ª finally å—é‡Œï¼Œwork_dir å°±æ²¡æœ‰è¢«åˆ é™¤
            try:
                logs_dir = os.path.join(repo_dir, ".build_logs")
                if not os.path.exists(logs_dir): 
                    os.makedirs(logs_dir)
                
                timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
                status_str = "SUCCESS" if build_success else "FAILED"
                
                # åˆ›å»ºå‹ç¼©åŒ…
                archive_name = f"{spec_name}-{status_str}-{timestamp}.tar.gz"
                archive_path = os.path.join(logs_dir, archive_name)
                
                print(f"[{tool_name}] ğŸ—„ï¸  Archiving history ({status_str})...")
                
                with tarfile.open(archive_path, "w:gz") as tar:
                    # arcname è®¾ç½®ä¸º 'build-log' å¯ä»¥åœ¨è§£å‹æ—¶ä¿æŒæ•´æ´
                    tar.add(log_source_dir, arcname=f"build-logs-{status_str}")
                
                print(f"[{tool_name}] History saved to: {archive_path}")

            except Exception as log_err:
                print(f"[{tool_name}] Warning: Failed to save history logs: {log_err}")

    # --- with å—ç»“æŸï¼Œwork_dir åœ¨æ­¤å¤„è¢«è‡ªåŠ¨æ¸…ç† ---

    # å¦‚æœæ„å»ºå¤±è´¥ï¼Œåœ¨è¿™é‡Œé€€å‡ºï¼Œä¸å†æ›´æ–° repodata
    if not build_success:
        return False

    # Step E: Update Index
    run_cmd(["createrepo_c", "--update", repo_dir])
    
    # --- ç‰¹æ€§ 4: GPG ç­¾å (Repo Level) ---
    if gpg_key_id:
        sign_repodata(repo_dir, gpg_key_id)
        
    print(f"[{tool_name}] Done!")
    
    return True

def main():
    parser = argparse.ArgumentParser(description="Local Copr (lc) - Secure Build Tool")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # Init
    p_init = subparsers.add_parser("init", help="Init new repo")
    p_init.add_argument("--repo", required=True)
    p_init.add_argument("--gpg-key", help="GPG Key ID to enable signing (e.g. 3AA5C0AD)")
    p_init.add_argument("--enable-rebuild", action="store_true", help="Enable automatic dependency rebuilds")
    p_init.set_defaults(func=do_init)
    p_init.set_defaults(func=do_init)

    # Delete
    p_del = subparsers.add_parser("remove", help="Delete a repo")
    p_del.add_argument("--repo", required=True)
    p_del.set_defaults(func=do_delete)

    # Build
    p_build = subparsers.add_parser("build", help="Build RPM")
    p_build.add_argument("--source", help="Source dir (required unless --chain)")
    p_build.add_argument("--torepo", required=True)
    p_build.add_argument("--spec", help="Specific spec")
    p_build.add_argument("--addrepo", action="append")
    p_build.add_argument("--use-ssd", action="store_true")
    p_build.add_argument("--use-tmp-ssd", action="store_true")
    p_build.add_argument("--jobs", type=int, help="Limit build cores (e.g. 8 to prevent OOM)")
    p_build.add_argument("--enable-network", action="store_true", help="Allow network access during build (default: offline)")
    p_build.add_argument("--max-mem", help="Limit max memory (e.g. 4G, 512M) using systemd-run")
    p_build.add_argument("--chain", help="Path to JSON build plan")
    p_build.set_defaults(func=do_build)

    args = parser.parse_args()
    if args.command == 'build':
        if not args.source and not args.chain:
            parser.error("Argument error: --source is required unless --chain is specified.")    
    args.func(args)

if __name__ == "__main__":
    main()